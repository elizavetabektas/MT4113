library(ggmosaic)
library(readr)
library(tidyverse)
#### Point the filePath to where you have downloaded the datasets to and
#### assign the data files to data.tables
filePath <- "/Users/yelizavetasalo/Desktop/qenv/"
transactionData <- fread(paste0(filePath,"QVI_transaction_data.csv"))
customerData <- fread(paste0(filePath,"QVI_purchase_behaviour.csv"))
#### Examine transaction data
head(transactionData)
head(customerData)
#### Convert DATE column to a date format
#### A quick search online tells us that CSV and Excel integer dates begin on 30 Dec 1899
transactionData$DATE <- as.Date(transactionData$DATE, origin = "1899-12-30")
#### Examine PROD_NAME
head(transactionData$PROD_NAME)
#### Examine the words in PROD_NAME to see if there are any incorrect entries
#### such as products that are not chips
productWords <- data.table(unlist(strsplit(unique(transactionData[, PROD_NAME]), " ")))
setnames(productWords, 'words')
#### Removing digits
productWordsDigits <- gsub("[[:digit:]]", "", as.matrix(productWords))
#### Removing special characters
productWordsChar <- gsub("[[:punct:]]", "", as.matrix(productWordsDigits))
#### Let's look at the most common words by counting the number of times a word appears and
#### sorting them by this frequency in order of highest to lowest frequency
vec3 <- as.data.frame(table(productWordsChar))
vec4 <- vec3[order(-vec3$Freq),]
vec4
#### Remove salsa products
transactionData[, SALSA := grepl("salsa", tolower(PROD_NAME))]
transactionData <- transactionData[SALSA == FALSE, ][, SALSA := NULL]
#### Summarise the data to check for nulls and possible outliers
summary(transactionData)
#### Filter the dataset to find the outlier
filter(transactionData, transactionData$PROD_QTY==200)
#### Let's see if the customer has had other transactions
filter(transactionData, transactionData$LYLTY_CARD_NBR==226000)
#### Filter out the customer based on the loyalty card number
transactionData <- subset(transactionData, transactionData$LYLTY_CARD_NBR!=226000)
#### Re-examine transaction data
summary(transactionData)
#### Count the number of transactions by date
vec5 <- as.data.frame(table(transactionData$DATE))
vec6 <- vec5[order(-vec5$Freq),]
names(vec6)[1] <- "DATE"
vec6
#### Create a sequence of dates and join this the count of transactions by date
vec7 <- as.data.frame(factor(seq(as.Date("2018-07-01"), as.Date("2019-06-30"), by="days")))
names(vec7)[1] <- "DATE"
transactions_by_day <- merge(vec7,vec6,all.x=TRUE)
names(transactions_by_day)[2] <- "N"
transactions_by_day[,1] <- as.Date(transactions_by_day[,1], format="%Y-%m-%d")
#### Setting plot themes to format graphs
theme_set(theme_bw())
theme_update(plot.title = element_text(hjust = 0.5))
#### Plot transactions over time
ggplot(transactions_by_day, aes(x = DATE, y = N)) +
geom_line() +
labs(x = "Day", y = "Number of transactions", title = "Transactions over time") +
scale_x_date(breaks = "1 month") +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5))
#### Filter to December and look at individual days
transactions_December <- transactions_by_day[grep("-12-",transactions_by_day$DATE),]
ggplot(transactions_December, aes(x = DATE, y = N)) +
geom_line() +
labs(x = "Day", y = "Number of transactions", title = "Transactions in December") +
scale_x_date(breaks = "1 day") +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5))
#### Pack size
#### We can work this out by taking the digits that are in PROD_NAME
transactionData[, PACK_SIZE := parse_number(PROD_NAME)]
#### Always check your output
#### Let's check if the pack sizes look sensible
transactionData[, .N, PACK_SIZE][order(PACK_SIZE)]
#### Let's plot a histogram of PACK_SIZE since we know that it is a categorical variable and not a continuous variable even though it is numeric.
hist(transactionData[, PACK_SIZE], xlab="Pack Size", main="Histogram of Pack Size")
#### Brands
vec9 <- c(1:length(transactionData$PROD_NAME))
for (i in 1:length(transactionData$PROD_NAME)){
vec9[i] <- word(transactionData$PROD_NAME[i])
}
#### Checking brands
transactionData$BRAND <- vec9
unique(vec9)
#### Clean brand names
transactionData[BRAND == "Red", BRAND := "RRD"]
#### Check again
unique(transactionData$BRAND)
transactionData[BRAND == "Sunbites", BRAND := "Snbts"]
transactionData[BRAND == "Natural", BRAND := "NCC"]
transactionData[BRAND == "Grain", BRAND := "GrnWves"]
transactionData[BRAND == "Woolworths", BRAND := "WW"]
transactionData[BRAND == "Infuzions", BRAND := "Infzns"]
transactionData[BRAND == "Smith", BRAND := "Smiths"]
transactionData[BRAND == "Dorito", BRAND := "Doritos"]
unique(transactionData$BRAND)
#### Examining customer data
summary(transactionData)
#### Merge transaction data to customer data
data <- merge(transactionData, customerData, all.x = TRUE)
colSums(is.na(data))
fwrite(data, paste0(filePath,"QVI_data.csv"))
#### Total sales by LIFESTAGE and PREMIUM_CUSTOMER
sb1 <- subset(data, select=c("LIFESTAGE","TOT_SALES","PREMIUM_CUSTOMER"))
sb11 <- aggregate(TOT_SALES~LIFESTAGE+PREMIUM_CUSTOMER, sb1, FUN=sum)
sb11$COMB <- paste(sb11$PREMIUM_CUSTOMER,sb11$LIFESTAGE)
ggplot(sb11, aes(x=factor(COMB), y=TOT_SALES)) + geom_col() + labs(y= "Total Sales", x = "Customer Segment (Lifestage and Premium Customer)")
#### Number of customers by LIFESTAGE and PREMIUM_CUSTOMER
sb3 <- subset(data, select=c("LYLTY_CARD_NBR","LIFESTAGE","PREMIUM_CUSTOMER"))
sb33 <- distinct(sb3,LYLTY_CARD_NBR,.keep_all = TRUE)
sb333 <- aggregate(LYLTY_CARD_NBR~LIFESTAGE+PREMIUM_CUSTOMER, sb33,FUN=length)
sb333$COMB <- paste(sb333$PREMIUM_CUSTOMER, sb333$LIFESTAGE)
sb333$CUS_NUM <- sb333$LYLTY_CARD_NBR
ggplot(sb333, aes(x=factor(COMB), y=CUS_NUM)) + geom_col() + labs(y= "Number of Customers", x = "Customer Segment (Lifestage and Premium Customer)")
#### Average number of units per customer by LIFESTAGE and PREMIUM_CUSTOMER
sb5 <- subset(data, select=c("PROD_QTY","LYLTY_CARD_NBR","LIFESTAGE","PREMIUM_CUSTOMER"))
sb55 <- aggregate(PROD_QTY~LYLTY_CARD_NBR+LIFESTAGE+PREMIUM_CUSTOMER, sb5, FUN=sum)
sb555 <- aggregate(PROD_QTY~LIFESTAGE+PREMIUM_CUSTOMER, sb55, FUN=mean)
sb555$COMB <- paste(sb555$PREMIUM_CUSTOMER, sb555$LIFESTAGE)
ggplot(sb555, aes(x=factor(COMB), y=PROD_QTY)) + geom_col() + labs(y= "Average Number of Units per Customer", x = "Customer Segment (Lifestage and Premium Customer)")
#### Average price per unit by LIFESTAGE and PREMIUM_CUSTOMER
sb7 <- subset(data, select=c("PROD_QTY","TOT_SALES","LIFESTAGE","PREMIUM_CUSTOMER"))
sb7$AV_PR <- (sb7$TOT_SALES)/(sb7$PROD_QTY)
sb7$COMB <- paste(sb7$PREMIUM_CUSTOMER, sb7$LIFESTAGE)
sb77 <- aggregate(AV_PR~COMB, sb7, FUN=mean)
ggplot(sb77, aes(x=factor(COMB), y=AV_PR)) + geom_col() + labs(y= "Average Price per Unit", x = "Customer Segment (Lifestage and Premium Customer)")
#### Perform an independent t-test between mainstream vs premium and budget midage and
#### young singles and couples
MAINSTREAM_MIDAGE <- subset(sb7, COMB=="Mainstream MIDAGE SINGLES/COUPLES")
MAINSTREAM_MIDAGE <- c(MAINSTREAM_MIDAGE$AV_PR)
PREMIUM_MIDAGE <- subset(sb7, COMB=="Premium MIDAGE SINGLES/COUPLES")
PREMIUM_MIDAGE <- c(PREMIUM_MIDAGE$AV_PR)
BUDGET_MIDAGE <- subset(sb7, COMB=="Budget MIDAGE SINGLES/COUPLES")
BUDGET_MIDAGE <- c(BUDGET_MIDAGE$AV_PR)
MIDAGE_COMBINED <- data.frame(cbind(MAINSTREAM_MIDAGE,PREMIUM_MIDAGE,BUDGET_MIDAGE))
MIDAGE_STACKED <- stack(MIDAGE_COMBINED)
MIDAGE_ANOVA <- aov(values~ind,data=MIDAGE_STACKED)
summary(MIDAGE_ANOVA)
MAINSTREAM_YOUNG <- subset(sb7, COMB=="Mainstream YOUNG SINGLES/COUPLES")
MAINSTREAM_YOUNG <- c(MAINSTREAM_YOUNG$AV_PR)
PREMIUM_YOUNG <- subset(sb7, COMB=="Premium YOUNG SINGLES/COUPLES")
PREMIUM_YOUNG <- c(PREMIUM_YOUNG$AV_PR)
BUDGET_YOUNG <- subset(sb7, COMB=="Budget YOUNG SINGLES/COUPLES")
BUDGET_YOUNG <- c(BUDGET_YOUNG$AV_PR)
YOUNG_COMBINED <- data.frame(cbind(MAINSTREAM_YOUNG,PREMIUM_YOUNG,BUDGET_YOUNG))
YOUNG_STACKED <- stack(YOUNG_COMBINED)
YOUNG_ANOVA <- aov(values~ind,data=YOUNG_STACKED)
summary(YOUNG_ANOVA)
# The t-test results in a p-value of <2e-16, i.e. the unit price for mainstream, young and mid-age singles and couples [ARE] significantly higher than that of budget or premium, young and midage singles and couples.
#### Deep dive into Mainstream, young singles/couples
MAINSTREAM_YOUNG_SC <- subset(data, PREMIUM_CUSTOMER=="Mainstream" & LIFESTAGE=="YOUNG SINGLES/COUPLES")
MAINSTREAM_YOUNG_SC <- subset(MAINSTREAM_YOUNG_SC, select=c("BRAND", "PACK_SIZE"))
POP_BRANDS1 <- as.data.frame(table(MAINSTREAM_YOUNG_SC$BRAND))
POP_BRANDS <- POP_BRANDS1[order(-POP_BRANDS1$Freq),]
head(POP_BRANDS)
tail(POP_BRANDS)
# [INSIGHTS]
# We can see that:
# The top 5 most popular chip brands are (from most to least): Kettle, Pringles, Doritos, Smiths, Infuzions and Thins
# The least popular chip brands are (from least to most): Burger, French, Sunbites, Cheetos and CCs
#### Preferred pack size compared to the rest of the population
# Over to you! Do the same for pack size.
POP_PACK1 <- as.data.frame(table(MAINSTREAM_YOUNG_SC$PACK_SIZE))
POP_PACK <- POP_PACK1[order(-POP_PACK1$Freq),]
head(POP_PACK)
tail(POP_PACK)
# [INSIGHTS]
# We can see that:
# The top 5 most popular pack sizes are (from most to least): 175g, 150g, 134g, 110g and 110g
# The 5 least popular pack sizes are (from least to most): 125g, 220g, 70g, 180g and 160g
a <- c(36,38,23,10,3,1,1,0,0)
sum <- 0
for (i in 1:9) {
summ=summ+(a[i]-9*0.18125)**2/(9*0.18125*(1-0.18125))
}
a <- c(36,38,23,10,3,1,1,0,0)
summ <- 0
for (i in 1:9) {
summ=summ+(a[i]-9*0.18125)**2/(9*0.18125*(1-0.18125))
}
summ
number <- 9*0.18125
vector <- c(36,48,38,23,10,3,1,1)
summ <- 0
for (i in 0:9) {
summ <- summ + vector[i]*(i-number)**2
}
summ
vector <- c(36,48,38,23,10,3,1,1,0,0)
summ <- 0
for (i in 0:9) {
summ <- summ + vector[i]*(i-number)**2
}
summ
qchisq(0.95,df=159)
pchisq(103.2,100)
pchisq(95,100)
ppois(280,320)
?n
?pnorm
pnorm((280.5-320)/sqrt(320))
pchisq(51.011,82)
pchisq(2.36,4)
pchisq(4.06,4)
1-pbinom(30,51,75/101)
pbinom(30,51,75/101)
pbinom(83,210,0.5)
pbinom(83,210,0.5)*2
pnorm(83.5,210*0.5,210*0.25)
?pnorm
pnorm(83.5,210*0.5,sqrt(210*0.5)
)
pnorm(-2.098)
pnorm(-2.098)*2
pbinom(83.5,210,1/3)
2*(1-pbinom(83.5,210,1/3))
(1-pbinom(83.5,210,1/3))
knitr::opts_chunk$set(echo = TRUE)
#= I use this all the time, thanks Hadley Wickham
library(tidyverse)
#= use the mcyle data in the MASS library
library(MASS)
data(mcycle)
head(mcycle)
p <- ggplot(data=mcycle) +
geom_point(aes(x=times, y=accel), col='purple', size=1.5) +
xlab('time (ms)') + ylab('acceleration') + ggtitle('A wiggly relationship') +
theme_light()
p
?ggplot
?data
?geom_point
?aes
?geom_point
# to emphasise the basis matrix - intercept and linear term.
f1Basis <- data.frame(y = mcycle$accel, x0 = 1, x1 = mcycle$times)
head(f1Basis)
?data.frame
?head
# No intercept, I've got it already
f1Fitted <- lm(y ~ . -1, data = f1Basis)
summary(f1Fitted)
f1Predicted <- f1Basis %>% mutate(yhat = fitted(f1Fitted)) %>% arrange(x1)
p + geom_line(data = f1Predicted, aes(x1, yhat), col = 'blue', alpha = 0.6)
?lm
?summary
?poly
?cbind
# a complex model
fbigFitted <- lm(accel ~ poly(times, 20), data = mcycle)
fbigPredicted <- mcycle %>% mutate(yhat = fitted(fbigFitted)) %>% arrange(times)
p + geom_line(data = fbigPredicted, aes(times, yhat), col = 'blue', alpha = 0.6)
# construct using "raw" polynomials - usually you'd use orthogonal, but those are details
f4Basis <- cbind(1, poly(mcycle$times, 4, raw = T))
head(f4Basis)
par(mfrow = c(2,3))
for(i in 1:5){
plot(mcycle$times, f4Basis[,i], xlab = "Time", ylab = "Basis value", type = 'l')
}
?poly
?par
?mfrow
?plot
?poly
?cbind
mcycle$times
poly(mcycle$times,4)
poly(mcycle$times,4,raw=T)
# fit that back to our data - several basis functions
f4Basis <- data.frame(y = mcycle$accel, f4Basis)
f4Fitted <- lm(y ~ ., data = f4Basis)
f4Predicted <- f4Basis %>% mutate(yhat = fitted(f4Fitted)) %>% arrange(X1)
p + geom_line(data = f4Predicted, aes(X1, yhat), col = 'blue', alpha = 0.6)
# make lots of f
basisList <- list()
for(i in 1:20){
basisList[[i]] <- data.frame(y = mcycle$accel, poly(mcycle$times, degree = i, raw = T))
}
# fit them all using OLS
modelList <- lapply(basisList, function(q){lm(y~., data = q)})
adjRsq <- lapply(modelList, function(q){summary(q)$adj.r.squared}) %>% unlist()
which.max(adjRsq)
bestModel <- basisList[[12]] %>% mutate(yhat = fitted(modelList[[12]])) %>% arrange(X1)
p + geom_line(data = bestModel, aes(X1, yhat), col = 'blue', alpha = 0.6)
# make lots of f
library(splines)
basisList <- list()
for(i in 1:20){
basisList[[i]] <- data.frame(y = mcycle$accel, bs(mcycle$times, df = i+2))
}
modelList <- lapply(basisList, function(q){lm(y~., data = q)})
adjRsq <- lapply(modelList, function(q){summary(q)$adj.r.squared}) %>% unlist()
which.max(adjRsq)
bestModel <- basisList[[9]] %>% mutate(yhat = fitted(modelList[[9]]))
p + geom_line(data = bestModel, aes(mcycle$times, yhat), col = 'blue', alpha = 0.6)
# create a train and validation set
set.seed(234324)
# about 60% for training
trainInd <- sample(1:nrow(mcycle), size = 80, replace = F)
trainDat <- mcycle[trainInd,]
validationDat <- mcycle[-trainInd,]
# make lots of f and fit them with OLS
error <- numeric(30)
for(i in 1:30){
currentModel <- lm(accel ~ bs(times, df = i+3, Boundary.knots = c(min(mcycle$times), max(mcycle$times))), data = trainDat)
yhat <- predict(currentModel, newdata = validationDat)
error[i] <- sum((validationDat$accel - yhat)^2)
}
plot(error, xlab = "Polynomial degree", ylab = "Validation error", type = 'b')
library(tidyverse)
ggplot(data=mpg) + geom_point(mapping=aes(x=displ,y=hwy)) + facet_wtap(~ class, nrow=2)
ggplot(data=mpg) + geom_point(mapping=aes(x=displ,y=hwy)) + facet_wrap(~ class, nrow=2)
ggplot(data=mpg) + geom_point(mapping=aes(x=displ,y=hwy)) + facet_wrap(drv ~ cyl)
ggplot(data=mpg) + geom_point(mapping=aes(x=displ,y=hwy)) + facet_wrap(drv ~ cyl)
ggplot(data=mpg) + geom_point(mapping=aes(x=displ,y=hwy)) + facet_grid(drv ~ cyl)
ggplot(data=mpg) + geom_point(mapping=aes(x=displ,y=hwy)) + facet_grid(. ~ cyl)
?mpg
ggplot(data=mpg) + geom_point(mapping=aes(x=displ,y=hwy)) + facet_grid(. ~ cty)
?mpg
ggplot(data=mpg) + geom_point(mapping=aes(x=displ,y=hwy)) + facet_grid(. ~ year)
ggplot(data=mpg) + geom_point(mapping=aes(x=displ,y=hwy)) + facet_wrap( ~ year)
ggplot(data=mpg) + geom_point(mapping=aes(x=displ,y=hwy)) + facet_grid(driv ~ .)
ggplot(data=mpg) + geom_point(mapping=aes(x=displ,y=hwy)) + facet_grid(drv ~ .)
ggplot(data=mpg) + geom_point(mapping=aes(x=displ,y=hwy)) + facet_grid(. ~ cyl)
ggplot(data=mpg) + geom_point(mapping=aes(x=displ,y=hwy)) + facet_wrap(~ class, nrow=2)
?facet_wrap
ggplot(data=mpg) + geom_point(mapping=aes(x=displ,y=hwy))
ggplot(data=mpg) + geom_smooth(mapping=aes(x=displ,y=hwy))
ggplot(data=mpg) + geom_smooth(mapping=aes(x=displ,linetype=drv))
ggplot(data=mpg) + geom_smooth(mapping=aes(x=displ,y=hwy,linetype=drv))
ggplot(data=mpg) + geom_smooth(mapping=aes(x=displ,y=hwy,linetype=drv))+ geom_point(mapping=aes(x=displ,y=hwy))
ggplot(data=mpg, mapping=aes(x=displ,y=hwy))
ggplot(data=mpg, mapping=aes(x=displ,y=hwy)) +geom_point() + geom_smooth()
ggplot(data=mpg, mapping=aes(x=displ,y=hwy)) +geom_point(mapping= aes(colour=class) + geom_smooth()
ggplot(data=mpg, mapping=aes(x=displ,y=hwy)) +geom_point(mapping= aes(colour=class))+ geom_smooth()
?geom_line
ggplot(data=mpg, mapping=aes(x=displ,y=hwy)) +geom_line()
ggplot(data=mpg, mapping=aes(x=displ,y=hwy)) +geom_path()
ggplot(data=mpg, mapping=aes(x=displ,y=hwy)) +geom_step()
ggplot(data=mpg, mapping=aes(x=displ,y=hwy)) +geom_line()
?geom_line
ggplot(data=mpg, mapping=aes(x=displ,y=hwy)) +geom_boxplot()
ggplot(data=mpg, mapping=aes(x=displ,y=hwy)) +geom_histogram()
ggplot(data=mpg, mapping=aes(x=displ,y=hwy)) +geom_area()
?geom_smooth
ggplot()
ggplot(data=mpg, mapping = aes(x=displ, y=hwy, color=drv)) +geom_point() +geom_smooth(se=FALSE)
ggplot(data=mpg, mapping = aes(x=displ, y=hwy, color=drv)) +geom_point() +geom_smooth()
ggplot(data=mpg, mapping = aes(x=displ, y=hwy)) +geom_point() +geom_smooth(data=filter(mpg,class=="suv"))
ggplot(data=mpg, mapping = aes(x=displ, y=hwy)) +geom_point() +geom_smooth(data=filter(mpg,class=="2seater"))
ggplot(data=mpg, mapping = aes(x=displ, y=hwy)) +geom_point() +geom_smooth()
ggplot(data=mpg, mapping = aes(x=displ, y=hwy)) +geom_point() +geom_smooth(se=FALSE)
ggplot(data=mpg, mapping = aes(x=displ, y=hwy)) +geom_point() +geom_smooth(se=FALSE, group=class)
ggplot(data=mpg, mapping = aes(x=displ, y=hwy)) +geom_point() +geom_smooth(se=FALSE, mappingaes(group=class)
ggplot(data=mpg, mapping = aes(x=displ, y=hwy)) +geom_point() +geom_smooth(se=FALSE, mapping=aes(group=class))
ggplot(data=mpg, mapping = aes(x=displ, y=hwy)) +geom_point() +geom_smooth(se=FALSE, mapping=aes(group=drv))
ggplot(data=mpg, mapping = aes(x=displ, y=hwy, color=class)) +geom_point() +geom_smooth(se=FALSE, mapping=aes(group=drv))
ggplot(data=mpg, mapping = aes(x=displ, y=hwy, color=class)) +geom_point() +geom_smooth(se=FALSE, mapping=aes(group=drv, color=class))
ggplot(data=mpg, mapping = aes(x=displ, y=hwy, color=drv)) +geom_point() +geom_smooth(se=FALSE))
ggplot(data=mpg, mapping = aes(x=displ, y=hwy, color=drv)) +geom_point() +geom_smooth(se=FALSE)
ggplot(data=mpg, mapping = aes(x=displ, y=hwy)) +geom_smooth(se=FALSE)+geom_point(mapping=aes( color=drv))
ggplot(data=mpg, mapping = aes(x=displ, y=hwy)) +geom_smooth(se=FALSE, mapping=aes(linetype=drv))+geom_point(mapping=aes( color=drv))
ggplot(data=mpg, mapping = aes(x=displ, y=hwy)) +geom_point(mapping=aes( color=drv))
ggplot(data=diamonds)+geom_bar(mapping=aes(x=cut))
?diamonds
?stat_summary
?stat_summary
?geom_bar
?geom_area
ggplot(data=diamonds)+geom_pointrange(mapping=aes(x=cut))
ggplot(data=diamonds)+geom_pointrange(mapping=aes(x=cut,y=depth),fun.ymin=min,fun.ymax=max,fun.y=median)
ggplot(data=diamonds)+geom_pointrange(mapping=aes(x=cut,y=depth))
ggplot(data=diamonds)+geom_pointrange(mapping=aes(x=cut,y=depth),fun.ymin=min,fun.ymax=max,fun.y=median)
?geom_pointrange
ggplot(data=diamonds)+geom_pointrange(mapping=aes(x=cut,y=depth),ymin=min,ymax=max)
ggplot(data=diamonds)+stat_summary(mapping=aes(x=cut,y=depth),fun.ymin=min,fun.ymax=max,fun.y=median)
ggplot(data=diamonds)+geom_pointrange(mapping=aes(x=cut,y=depth),fun.min=min,fun.max=max,fun.y=median)
ggplot(data=diamonds)+geom_pointrange(mapping=aes(x=cut,y=depth),ymin=min,ymax=max)
ggplot(data=diamonds)+geom_bar(mapping=aes(x=cut))
ggplot(data=diamonds)+geom_col(mapping=aes(x=cut))
ggplot(data=diamonds)+geom_col(mapping=aes(x=cut,y=..prop..))
ggplot(data=diamonds)+geom_col(mapping=aes(x=cut,y=depth))
ggplot(data=diamonds)+geom_bar(mapping=aes(x=cut,y=depth))
?stat_smooth
ggplot(data=diamonds)+geom_bar(mapping=aes(x=cut,y=..prop..,group=1))
ggplot(data=diamonds)+geom_bar(mapping=aes(x=cut,y=..prop..))
ggplot(data=diamonds)+geom_bar(mapping=aes(x=cut,y=..prop..,fill=color))
ggplot(data=diamonds)+geom_bar(mapping=aes(x=cut,y=..prop..,fill=color,group=1))
ggplot(data=diamonds)+geom_bar(mapping=aes(x=cut,y=..prop..,group=2))
ggplot(data=diamonds)+geom_bar(mapping=aes(x=cut,y=..prop..,group=1))
ggplot(data=diamonds)+geom_bar(mapping=aes(x=cut,y=..prop..,group))
ggplot(data=diamonds)+geom_bar(mapping=aes(x=cut,y=..prop..,group=0))
ggplot(data=diamonds)+geom_bar(mapping=aes(x=cut,y=..prop..))
ggplot(data=diamonds,mapping=aes(x=cut,fill=clarity)) + geom_bar(alpha=1/5,position="identity")
ggplot(data=diamonds,mapping=aes(x=cut,fill=clarity)) + geom_bar()
ggplot(data=diamonds,mapping=aes(x=cut,fill=clarity)) + geom_bar(alpha=1/5,position="identity")
ggplot(data=diamonds,mapping=aes(x=cut,fill=clarity)) + geom_bar(fill=NA,position="identity")
ggplot(data=diamonds,mapping=aes(x=cut,color=clarity)) + geom_bar(fill=NA,position="identity")
ggplot(data=diamonds) + geom_bar(mapping=aes(x=cut,fill=clarity),position="fill")
ggplot(data=diamonds) + geom_bar(mapping=aes(x=cut,fill=clarity),position="dodge")
ggplot(data=mpg,mapping=aes(x=cty,y=hwy)) + geom_point()
ggplot(data=mpg,mapping=aes(x=cty,y=hwy)) + geom_jitter()
?position_jitter
?geom_jitter
ggplot(data=mpg,mapping=aes(x=cty,y=hwy)) + geom_jitter()
ggplot(data=mpg,mapping=aes(x=cty,y=hwy)) + geom_jitter(width=0.01)
ggplot(data=mpg,mapping=aes(x=cty,y=hwy)) + geom_jitter(width=0.1)
ggplot(data=mpg,mapping=aes(x=cty,y=hwy)) + geom_jitter()
ggplot(data=mpg,mapping=aes(x=cty,y=hwy)) + geom_jitter(width=0.4)
ggplot(data=mpg,mapping=aes(x=cty,y=hwy)) + geom_jitter()
ggplot(data=mpg,mapping=aes(x=cty,y=hwy)) + geom_count()
?geom_boxplot
ggplot(data=diamonds) + geom_bar(mapping=aes(x=cut,fill=clarity),position="dodge")
ggplot(data=diamonds) + geom_bar(mapping=aes(x=cut,fill=clarity),position="dodge2")
ggplot(data=diamonds) + geom_bar(mapping=aes(x=cut,fill=clarity),position="dodge")
ggplot(data=diamonds) + geom_boxplot(mapping=aes(x=cut,fill=clarity),position="dodge")
ggplot(data=diamonds) + geom_boxplot(mapping=aes(x=cut,fill=clarity),position="dodge2")
ggplot(data=diamonds) + geom_boxplot(mapping=aes(x=cut),position="dodge2")
ggplot(data=mpg,mapping=aes(x=class,y=hwy)) + geom_boxplot()
ggplot(data=mpg,mapping=aes(x=class,y=hwy)) + geom_boxplot(position="dodge")
ggplot(data=mpg,mapping=aes(x=class,y=hwy)) + geom_boxplot(position="dodge2")
ggplot(data=mpg,mapping=aes(x=class,y=hwy)) + geom_boxplot() +coord_flip()
ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, fill = clarity))
ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, fill = clarity)) + coord_polar()
ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, fill = clarity))
ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, fill = clarity)) + coord_polar() + coord_flip()
ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, fill = clarity)) + coord_polar()
ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, fill = clarity)) + facet_wrap(~clarity)
ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, fill = clarity)) + facet_wrap(~clarity) + coord_polar()
ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, y = clarity)) + facet_wrap(~clarity) + coord_polar()
?labs()
ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, fill = clarity)) + coord_polar()
ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, fill = clarity)) + coord_polar() + labs(title="The title of this graph")
ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, fill = clarity)) + coord_polar() + labs(title="The title of this graph") + xlab("Diamond Cut")
ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, fill = clarity)) + coord_polar() + labs(title="The title of this graph") + xlab("Diamond Cut") + ylab("Y AXISSSS")
?coord_quickmao
?coord_quickmap
ggplot(data=mpg, mapping = aes(x=cty,y=hwy)) + geom_point()
ggplot(data=mpg, mapping = aes(x=cty,y=hwy)) + geom_point() + geom_abline()
ggplot(data=mpg, mapping = aes(x=cty,y=hwy)) + geom_jitter() + geom_abline()
ggplot(data=mpg, mapping = aes(x=cty,y=hwy)) + geom_point() + geom_abline() + coord_fixed()
ggplot(data=mpg, mapping = aes(x=cty,y=hwy)) + geom_jitter() + geom_abline()
ggplot(data=mpg, mapping = aes(x=cty,y=hwy)) + geom_point() + geom_abline() + coord_fixed()
?coord_fixed
?geom_abline
ggplot(data=mpg, mapping = aes(x=cty,y=hwy)) + geom_abline() + coord_fixed()
?geom_abline
ggplot(data=mpg, mapping = aes(x=cty,y=hwy)) + geom_point() + geom_abline() + coord_fixed()
ggplot(data=mpg, mapping = aes(x=cty,y=hwy)) + geom_point() + geom_abline(2) + coord_fixed()
>pie
?pie
this_is_a_really_long_name <- 2.5
this_is_a_really_long_name
this_is_also <- 5
this_is_a_really_long_name <- 3.5
library(tidyverse)
library(nycflights13)
library(nycflights13)
install.packages(nycflights13)
install.package(nycflights13)
install.packages("nycflights13")
library(nycflights13)
flights
f <- factor(c('one', 'two', 'three'))
f
setwd("~/Desktop/MT4113")
# load package
library(DAAG)
install.packages('DAAG')
source("~/.active-rstudio-document")
install.packages("DAAG")
source("~/Desktop/MT4113/Untitled.R")
# load package
library(DAAG)
# load package
library(DAAG)
remove.packages("DAAG")
install.packages("DAAG")
# load package
library(DAAG)
# load SOI data
data(bomsoi)
# extract yearly averages
soi <- bomsoi$SOI
# extract year vector
year <- bomsoi$Year
est.mu <- mean(soi)
est.sd <- sd(soi)
est.mu
est
# simulate values and plot histogram on probability density scale
x <- rnorm(1000, est.mu, est.sd)
hist(x, prob = TRUE, ylim = c(0, 0.06))
gr <- seq(-25, 25, 0.01)
# compute exact PDF on grid and plot
lines(gr, dnorm(gr, est.mu, est.sd), col = "steelblue", lwd = 1.5)
# simulate values and plot histogram on probability density scale
x <- rnorm(1000000, est.mu, est.sd)
hist(x, prob = TRUE, ylim = c(0, 0.06))
gr <- seq(-25, 25, 0.01)
# compute exact PDF on grid and plot
lines(gr, dnorm(gr, est.mu, est.sd), col = "steelblue", lwd = 1.5)
# simulate values and plot histogram on probability density scale
x <- rnorm(100000000000, est.mu, est.sd)
hist(x, prob = TRUE, ylim = c(0, 0.06))
gr <- seq(-25, 25, 0.01)
# compute exact PDF on grid and plot
lines(gr, dnorm(gr, est.mu, est.sd), col = "steelblue", lwd = 1.5)
# simulate values and plot histogram on probability density scale
x <- rnorm(1000000000, est.mu, est.sd)
hist(x, prob = TRUE, ylim = c(0, 0.06))
